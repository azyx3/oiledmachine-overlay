--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_dma_buf.c.orig	2019-05-13 17:57:34.720004496 -0700
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_dma_buf.c	2019-05-13 18:22:31.208135685 -0700
@@ -140,60 +140,6 @@ int amdgpu_gem_prime_mmap(struct drm_gem
 	return ret;
 }
 
-/**
- * amdgpu_gem_prime_import_sg_table - &drm_driver.gem_prime_import_sg_table
- * implementation
- * @dev: DRM device
- * @attach: DMA-buf attachment
- * @sg: Scatter/gather table
- *
- * Imports shared DMA buffer memory exported by another device.
- *
- * Returns:
- * A new GEM BO of the given DRM device, representing the memory
- * described by the given DMA-buf attachment and scatter/gather table.
- */
-struct drm_gem_object *
-amdgpu_gem_prime_import_sg_table(struct drm_device *dev,
-				 struct dma_buf_attachment *attach,
-				 struct sg_table *sg)
-{
-	struct reservation_object *resv = attach->dmabuf->resv;
-	struct amdgpu_device *adev = dev->dev_private;
-	struct amdgpu_bo *bo;
-	struct amdgpu_bo_param bp;
-	int ret;
-
-	memset(&bp, 0, sizeof(bp));
-	bp.size = attach->dmabuf->size;
-	bp.byte_align = PAGE_SIZE;
-	bp.domain = AMDGPU_GEM_DOMAIN_CPU;
-	bp.flags = 0;
-	bp.type = ttm_bo_type_sg;
-	bp.resv = resv;
-	ww_mutex_lock(&resv->lock, NULL);
-	ret = amdgpu_bo_create(adev, &bp, &bo);
-	if (ret)
-		goto error;
-
-	bo->tbo.sg = sg;
-	bo->tbo.ttm->sg = sg;
-	bo->allowed_domains = AMDGPU_GEM_DOMAIN_GTT;
-	bo->preferred_domains = AMDGPU_GEM_DOMAIN_GTT;
-
-#if DRM_VERSION_CODE >= DRM_VERSION(4, 17, 0) || !defined(BUILD_AS_DKMS)
-	if (attach->dmabuf->ops != &amdgpu_dmabuf_ops)
-#endif
-		bo->prime_shared_count = 1;
-
-	ww_mutex_unlock(&resv->lock);
-	return &bo->gem_base;
-
-error:
-	ww_mutex_unlock(&resv->lock);
-	return ERR_PTR(ret);
-}
-
 static int
 __reservation_object_make_exclusive(struct reservation_object *obj)
 {
@@ -249,11 +195,11 @@ err_fences_put:
  * Returns:
  * 0 on success or a negative error code on failure.
  */
-static int amdgpu_gem_map_attach(struct dma_buf *dma_buf,
+static int amdgpu_dma_buf_map_attach(struct dma_buf *dma_buf,
 #if LINUX_VERSION_CODE < KERNEL_VERSION(4, 19, 0)
-				 struct device *target_dev,
+				     struct device *target_dev,
 #endif
-				 struct dma_buf_attachment *attach)
+				     struct dma_buf_attachment *attach)
 {
 	struct drm_gem_object *obj = dma_buf->priv;
 	struct amdgpu_bo *bo = gem_to_amdgpu_bo(obj);
--- a/drivers/gpu/drm/amd/amdgpu/amdgpu_gem.h.orig	2019-05-13 17:55:03.624140350 -0700
+++ b/drivers/gpu/drm/amd/amdgpu/amdgpu_gem.h	2019-05-13 18:24:51.523559497 -0700
@@ -39,29 +39,11 @@ int amdgpu_gem_object_open(struct drm_ge
 void amdgpu_gem_object_close(struct drm_gem_object *obj,
 				struct drm_file *file_priv);
 unsigned long amdgpu_gem_timeout(uint64_t timeout_ns);
-struct sg_table *amdgpu_gem_prime_get_sg_table(struct drm_gem_object *obj);
-struct drm_gem_object *
-amdgpu_gem_prime_import_sg_table(struct drm_device *dev,
-				 struct dma_buf_attachment *attach,
-				 struct sg_table *sg);
-struct dma_buf *amdgpu_gem_prime_export(struct drm_device *dev,
-					struct drm_gem_object *gobj,
-					int flags);
-#if DRM_VERSION_CODE >= DRM_VERSION(4, 17, 0)
-struct drm_gem_object *amdgpu_gem_prime_import(struct drm_device *dev,
-					    struct dma_buf *dma_buf);
-#endif
-struct reservation_object *amdgpu_gem_prime_res_obj(struct drm_gem_object *);
-void *amdgpu_gem_prime_vmap(struct drm_gem_object *obj);
-void amdgpu_gem_prime_vunmap(struct drm_gem_object *obj, void *vaddr);
-int amdgpu_gem_prime_mmap(struct drm_gem_object *obj, struct vm_area_struct *vma);
 #if LINUX_VERSION_CODE < KERNEL_VERSION(4, 17, 0)
 int amdgpu_gem_prime_pin(struct drm_gem_object *obj);
 void amdgpu_gem_prime_unpin(struct drm_gem_object *obj);
 #endif
 
-extern const struct dma_buf_ops amdgpu_dmabuf_ops;
-
 /*
  * GEM objects.
  */
